{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\t124\t79\t53\t50\t73\t50\t63\t67\t75\t\n",
      "57\t45\t75\t44\t41\t33\t42\t93\t67\t80\t\n",
      "54\t136\t76\t49\t41\t64\t83\t49\t64\t49\t\n",
      "62\t50\t50\t42\t46\t32\t47\t42\t66\t58\t\n",
      "105\t40\t70\t56\t57\t70\t20\t35\t151\t73\t\n",
      "86\t65\t79\t41\t50\t39\t111\t49\t65\t67\t\n",
      "117\t89\t59\t108\t79\t65\t72\t96\t62\t101\t\n",
      "112\t128\t78\t73\t80\t50\t65\t53\t94\t154\t\n",
      "51\t76\t48\t55\t57\t78\t98\t57\t113\t154\t\n",
      "50\t58\t85\t63\t55\t70\t54\t56\t66\t55\t\n",
      "52\t53\t50\t75\t34\t81\t44\t61\t58\t80\t\n",
      "48\t58\t113\t57\t59\t37\t52\t56\t65\t105\t\n",
      "69\t166\t64\t65\t36\t62\t65\t64\t59\t93\t\n",
      "77\t81\t116\t91\t71\t46\t81\t61\t63\t43\t\n",
      "158\t93\t106\t44\t36\t72\t60\t76\t90\t76\t\n",
      "63\t130\t77\t49\t106\t100\t40\t83\t95\t119\t\n",
      "74\t130\t163\t97\t78\t103\t92\t154\t125\t139\t\n",
      "126\t99\t145\t84\t200\t149\t105\t200\t157\t174\t\n",
      "81\t127\t71\t152\t61\t145\t58\t62\t200\t96\t\n",
      "150\t83\t152\t75\t170\t175\t82\t71\t170\t173\t\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import chainer\n",
    "import collections\n",
    "import numpy as np\n",
    "import itertools\n",
    "import math\n",
    "import copy\n",
    "import random\n",
    "\n",
    "env = gym.make(\"CartPole-v0\")#.unwrapped\n",
    "\n",
    "n_input = env.observation_space.shape[0]\n",
    "n_output = env.action_space.n\n",
    "\n",
    "def _conf_of(**kwargs):\n",
    "    return collections.namedtuple(\"_Conf\", kwargs.keys())(**kwargs)\n",
    "\n",
    "args = _conf_of(\n",
    "    n_middle = 50,\n",
    "    lr = 1e-2,\n",
    "    gamma = 0.95,\n",
    "    n_batch = 32,\n",
    "    n_episodes=200,\n",
    "    n_start_train=500,\n",
    "    n_target_update_interval=100,\n",
    "    n_steps=200,\n",
    "    epsilon=0.3,\n",
    ")\n",
    "\n",
    "class Model(chainer.Chain):\n",
    "\n",
    "    def __init__(self, n_input, n_middle, n_ouput):\n",
    "        super().__init__()\n",
    "        with self.init_scope():\n",
    "            self.l1 = chainer.links.Linear(n_input, n_middle)\n",
    "            self.l2 = chainer.links.Linear(n_middle, n_middle)\n",
    "            self.l3 = chainer.links.Linear(n_middle, n_output)\n",
    "            \n",
    "    def __call__(self, input):\n",
    "        h = chainer.functions.tanh(self.l1(input))\n",
    "        h = chainer.functions.tanh(self.l2(h))\n",
    "        return self.l3(h)\n",
    "\n",
    "        \n",
    "model = Model(n_input, 50, n_output)\n",
    "target_model = copy.deepcopy(model)\n",
    "\n",
    "\n",
    "def copy_param(target_link, source_link):\n",
    "    \"\"\"Copy parameters of a link to another link.\"\"\"\n",
    "    target_params = dict(target_link.namedparams())\n",
    "    for param_name, param in source_link.namedparams():\n",
    "        target_params[param_name].data[:] = param.data\n",
    "\n",
    "    # Copy Batch Normalization's statistics\n",
    "    target_links = dict(target_link.namedlinks())\n",
    "    for link_name, link in source_link.namedlinks():\n",
    "        if isinstance(link, torch.links.BatchNormalization):\n",
    "            target_bn = target_links[link_name]\n",
    "            target_bn.avg_mean[:] = link.avg_mean\n",
    "            target_bn.avg_var[:] = link.avg_var\n",
    "\n",
    "\n",
    "#opt = chainer.optimizers.Adam(eps=1e-2)\n",
    "opt = chainer.optimizers.SGD(lr=1e-2)\n",
    "opt.setup(model)\n",
    "\n",
    "buffer = []\n",
    "episode_result_list = []\n",
    "i_total_step = -1\n",
    "for i_episode in range(1, args.n_episodes + 1):\n",
    "    si = env.reset()\n",
    "    step_result_list = []\n",
    "    for i_step in range(1, args.n_steps + 1):\n",
    "        i_total_step += 1\n",
    "        \n",
    "        if random.random() < args.epsilon:\n",
    "            ai1 = env.action_space.sample()\n",
    "        else:\n",
    "            with chainer.no_backprop_mode():\n",
    "                ai1 = int(model(chainer.Variable(np.array([si], dtype=np.float32))).data.argmax(axis=1)[0])\n",
    "        si1, ri1, done, debug_info = env.step(ai1)\n",
    "        buffer.append(dict(si=si, ai1=ai1, ri1=ri1, si1=si1, done=done))\n",
    "        metric = None\n",
    "        if i_total_step > args.n_start_train:\n",
    "            batch = random.sample(buffer, args.n_batch)\n",
    "            batch = dict(\n",
    "                si=np.array([t[\"si\"] for t in batch], dtype=np.float32),\n",
    "                ai1=np.array([t[\"ai1\"] for t in batch], dtype=int),\n",
    "                ri1=np.array([t[\"ri1\"] for t in batch], dtype=np.float32),\n",
    "                si1=np.array([t[\"si1\"] for t in batch], dtype=np.float32),\n",
    "                mask=np.array([not t[\"done\"] for t in batch], dtype=np.float32),\n",
    "            )\n",
    "            q_pred = chainer.functions.reshape(chainer.functions.select_item(model(chainer.Variable(batch[\"si\"])), chainer.Variable(batch[\"ai1\"])), (-1, 1))\n",
    "            with chainer.no_backprop_mode():\n",
    "                q_target = (\n",
    "                    chainer.Variable(batch[\"ri1\"])\n",
    "                    + args.gamma*chainer.Variable(batch[\"mask\"])*chainer.functions.select_item(target_model(chainer.Variable(batch[\"si1\"])), chainer.Variable(model(chainer.Variable(batch[\"si1\"])).data.argmax(axis=1)))\n",
    "                ).data.reshape(-1, 1)\n",
    "            loss = chainer.functions.mean(chainer.functions.huber_loss(q_pred, chainer.Variable(q_target), delta=1))\n",
    "            model.cleargrads()\n",
    "            loss.backward()\n",
    "            opt.update()\n",
    "        if metric is not None:\n",
    "            q_list.append(np.mean(metric[\"q_pred\"]))\n",
    "            step_result_list.append(metric)\n",
    "        if i_total_step%(args.n_target_update_interval) == 0:\n",
    "            target_model = copy.deepcopy(model)\n",
    "        if done:\n",
    "            break\n",
    "        si = si1\n",
    "    episode_result_list.append(step_result_list)\n",
    "    print(i_step, end=\"\\t\")\n",
    "    if i_episode%10 == 0:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = Model(4, 50, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23128141"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm.l1.W.data.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020486917"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm.l2.W.data.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017133638"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm.l3.W.data.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
