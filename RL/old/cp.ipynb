{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\t58\t39\t44\t43\t39\t51\t38\t35\t39\t\n",
      "52\t56\t16\t12\t10\t51\t9\t17\t39\t35\t\n",
      "23\t37\t26\t53\t60\t63\t50\t62\t77\t35\t\n",
      "114\t95\t121\t86\t100\t72\t138\t52\t54\t186\t\n",
      "86\t51\t137\t97\t30\t36\t88\t57\t57\t101\t\n",
      "200\t200\t164\t152\t131\t132\t200\t200\t158\t160\t\n",
      "160\t78\t200\t200\t160\t189\t200\t176\t200\t192\t\n",
      "167\t143\t22\t133\t48\t200\t143\t181\t200\t200\t\n",
      "200\t192\t200\t184\t200\t200\t200\t177\t200\t200\t\n",
      "200\t200\t168\t200\t200\t200\t144\t200\t180\t186\t\n",
      "37\t200\t200\t165\t200\t176\t200\t200\t110\t186\t\n",
      "189\t200\t200\t200\t200\t200\t200\t200\t200\t200\t\n",
      "200\t200\t200\t175\t200\t200\t200\t200\t200\t200\t\n",
      "199\t197\t200\t194\t200\t104\t186\t200\t200\t200\t\n",
      "190\t200\t200\t113\t200\t200\t200\t173\t200\t200\t\n",
      "181\t200\t99\t200\t197\t200\t200\t53\t200\t194\t\n",
      "22\t200\t200\t200\t200\t200\t200\t200\t200\t25\t\n",
      "200\t64\t189\t200\t200\t24\t200\t200\t200\t200\t\n",
      "200\t200\t200\t50\t200\t39\t200\t200\t200\t200\t\n",
      "16\t200\t200\t200\t200\t200\t200\t200\t200\t200\t\n",
      "200\t200\t200\t200\t200\t200\t200\t200\t171\t159\t\n",
      "200\t200\t200\t37\t67\t200\t200\t200\t200\t200\t\n",
      "78\t200\t200\t200\t200\t200\t200\t200\t200\t200\t\n",
      "148\t200\t200\t200\t141\t200\t200\t200\t200\t200\t\n",
      "200\t200\t200\t200\t200\t200\t42\t200\t200\t121\t\n",
      "200\t200\t200\t200\t200\t200\t200\t68\t167\t200\t\n",
      "160\t185\t73\t105\t200\t81\t116\t200\t200\t200\t\n",
      "200\t200\t33\t200\t193\t101\t200\t132\t79\t200\t\n",
      "200\t182\t200\t200\t187\t200\t200\t200\t200\t127\t\n",
      "54\t200\t200\t62\t200\t171\t200\t200\t200\t200\t\n",
      "80\t200\t200\t200\t83\t95\t169\t200\t200\t200\t\n",
      "200\t200\t159\t120\t200\t200\t200\t200\t46\t72\t\n",
      "200\t200\t200\t200\t200\t200\t200\t200\t200\t200\t\n",
      "186\t180\t196\t200\t200\t200\t200\t121\t157\t160\t\n",
      "200\t200\t173\t151\t200\t76\t200\t200\t149\t141\t\n",
      "200\t120\t200\t200\t200\t190\t200\t200\t200\t200\t\n",
      "200\t114\t200\t124\t199\t24\t21\t17\t200\t39\t\n",
      "200\t200\t200\t135\t37\t200\t14\t30\t200\t145\t\n",
      "40\t200\t19\t136\t68\t127\t87\t78\t193\t186\t\n",
      "100\t195\t200\t200\t200\t183\t200\t190\t200\t109\t\n",
      "200\t46\t180\t200\t200\t188\t181\t96\t178\t105\t\n",
      "200\t178\t198\t99\t160\t200\t19\t164\t67\t180\t\n",
      "188\t200\t200\t78\t179\t38\t55\t200\t200\t156\t\n",
      "200\t200\t52\t200\t109\t108\t171\t70\t33\t167\t\n",
      "182\t39\t187\t147\t200\t69\t200\t165\t196\t158\t\n",
      "146\t143\t127\t57\t165\t200\t143\t133\t160\t103\t\n",
      "200\t70\t119\t96\t134\t160\t156\t74\t200\t74\t\n",
      "142\t139\t92\t138\t32\t200\t67\t172\t200\t180\t\n",
      "14\t178\t179\t195\t200\t200\t194\t46\t47\t64\t\n",
      "172\t47\t65\t41\t171\t32\t41\t200\t145\t200\t\n",
      "51\t28\t200\t200\t38\t200\t42\t169\t91\t79\t\n",
      "94\t156\t78\t155\t200\t178\t68\t26\t52\t196\t\n",
      "200\t200\t178\t187\t96\t200\t156\t133\t23\t151\t\n",
      "172\t134\t171\t122\t189\t187\t151\t198\t137\t200\t\n",
      "200\t80\t142\t110\t200\t15\t200\t81\t101\t87\t\n",
      "195\t200\t164\t184\t200\t200\t200\t192\t49\t169\t\n",
      "158\t194\t193\t199\t34\t17\t168\t148\t81\t154\t\n",
      "188\t200\t200\t200\t55\t152\t14\t127\t21\t200\t\n",
      "199\t12\t200\t200\t200\t183\t200\t76\t79\t197\t\n",
      "149\t23\t200\t63\t35\t93\t14\t120\t46\t200\t\n",
      "200\t200\t200\t200\t200\t20\t200\t200\t200\t56\t\n",
      "200\t200\t191\t200\t200\t200\t106\t20\t171\t73\t\n",
      "187\t177\t28\t130\t78\t186\t200\t32\t47\t200\t\n",
      "200\t185\t200\t84\t200\t200\t44\t200\t200\t96\t\n",
      "200\t200\t200\t123\t180\t123\t199\t102\t182\t192\t\n",
      "200\t150\t193\t200\t200\t192\t46\t47\t49\t93\t\n",
      "66\t69\t"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-2173a302ecd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mai1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mftn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvolatile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0msi1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mri1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mai1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mai1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mai1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mri1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mri1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msi1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msi1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import torch\n",
    "import collections\n",
    "import numpy as np\n",
    "import itertools\n",
    "import math\n",
    "import copy\n",
    "import random\n",
    "\n",
    "env = gym.make(\"CartPole-v0\")#.unwrapped\n",
    "\n",
    "n_input = env.observation_space.shape[0]\n",
    "n_output = env.action_space.n\n",
    "\n",
    "def _make_namer():\n",
    "    tbl = dict()\n",
    "    seen = set()\n",
    "    def namer(name):\n",
    "        if name in tbl:\n",
    "            tbl[name] += 1\n",
    "        else:\n",
    "            tbl[name] = 0\n",
    "        ret = f\"{name}_{tbl[name]}\"\n",
    "        assert ret not in seen\n",
    "        seen.add(ret)\n",
    "        return ret\n",
    "    return namer\n",
    "\n",
    "\n",
    "namer = _make_namer()\n",
    "act = torch.nn.Tanh\n",
    "var = torch.autograd.Variable\n",
    "ftn = torch.FloatTensor\n",
    "ltn = torch.LongTensor\n",
    "btn = torch.ByteTensor\n",
    "\n",
    "def _conf_of(**kwargs):\n",
    "    return collections.namedtuple(\"_Conf\", kwargs.keys())(**kwargs)\n",
    "\n",
    "\n",
    "args = _conf_of(\n",
    "    n_middle = 50,\n",
    "    lr = 1e-2,\n",
    "    gamma = 0.95,\n",
    "    n_batch = 32,\n",
    "    n_episodes=2000,\n",
    "    n_start_train=500,\n",
    "    n_target_update_interval=100,\n",
    "    n_steps=200,\n",
    "    epsilon=0.3,\n",
    ")\n",
    "\n",
    "\n",
    "model = torch.nn.Sequential(collections.OrderedDict((\n",
    "    (namer(\"fc\"), torch.nn.Linear(n_input, args.n_middle)),\n",
    "    (namer(\"ac\"), act()),\n",
    "    (namer(\"fc\"), torch.nn.Linear(args.n_middle, args.n_middle)),\n",
    "    (namer(\"ac\"), act()),\n",
    "    (\"output\", torch.nn.Linear(args.n_middle, n_output)),\n",
    ")))\n",
    "def _init(m):\n",
    "    if type(m) == torch.nn.Linear:\n",
    "        torch.nn.init.kaiming_uniform(m.weight.data)\n",
    "        m.weight.data.mul_(math.sqrt(1/2))\n",
    "        m.bias.data.fill_(0)\n",
    "model.apply(_init)\n",
    "target_model = copy.deepcopy(model)\n",
    "#opt = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "opt = torch.optim.Adam(model.parameters(), eps=1e-2)\n",
    "#opt = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.1)\n",
    "#opt = torch.optim.SGD(model.parameters(), lr=args.lr)\n",
    "\n",
    "buffer = []\n",
    "episode_result_list = []\n",
    "i_total_step = -1\n",
    "for i_episode in range(1, args.n_episodes + 1):\n",
    "    si = env.reset()\n",
    "    step_result_list = []\n",
    "    for i_step in range(1, args.n_steps + 1):\n",
    "        i_total_step += 1\n",
    "        \n",
    "        if random.random() < args.epsilon:\n",
    "            ai1 = env.action_space.sample()\n",
    "        else:\n",
    "            model.eval()\n",
    "            ai1 = int(model(var(ftn([si]), volatile=True)).max(1)[1].data.numpy()[0])\n",
    "        si1, ri1, done, debug_info = env.step(ai1)\n",
    "        buffer.append(dict(si=si, ai1=ai1, ri1=ri1, si1=si1, done=done))\n",
    "        metric = None\n",
    "        if i_total_step > args.n_start_train:\n",
    "            batch = random.sample(buffer, args.n_batch)\n",
    "            batch = dict(\n",
    "                si=ftn([t[\"si\"] for t in batch]),\n",
    "                ai1=ltn([t[\"ai1\"] for t in batch]).view(-1, 1),\n",
    "                ri1=ftn([t[\"ri1\"] for t in batch]).view(-1, 1),\n",
    "                si1=ftn([t[\"si1\"] for t in batch]),\n",
    "                mask=ftn([not t[\"done\"] for t in batch]).view(-1, 1),\n",
    "            )\n",
    "            model.train()\n",
    "            q_pred = model(var(batch[\"si\"])).gather(1, var(batch[\"ai1\"]))\n",
    "            target_model.eval()\n",
    "            model.eval()\n",
    "            mask = var(batch[\"mask\"], volatile=True)\n",
    "            #print(\"si\", batch[\"si\"])\n",
    "            #print(\"si1\", batch[\"si1\"])\n",
    "            q_target = (\n",
    "                var(batch[\"ri1\"], volatile=True)\n",
    "                + args.gamma*mask*target_model(var(batch[\"si1\"], volatile=True)).gather(1, model(var(batch[\"si1\"], volatile=True)).max(1)[1].view(-1, 1))\n",
    "            )\n",
    "            q_target.volatile = False\n",
    "            loss = torch.nn.SmoothL1Loss()(q_pred, q_target)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        if metric is not None:\n",
    "            q_list.append(np.mean(metric[\"q_pred\"]))\n",
    "            step_result_list.append(metric)\n",
    "        if i_total_step%(args.n_target_update_interval) == 0:\n",
    "            target_model = copy.deepcopy(model)\n",
    "        if done:\n",
    "            break\n",
    "        si = si1\n",
    "    episode_result_list.append(step_result_list)\n",
    "    print(i_step, end=\"\\t\")\n",
    "    if i_episode%10 == 0:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (fc_0): Linear(in_features=4, out_features=50)\n",
       "  (ac_0): Tanh()\n",
       "  (fc_1): Linear(in_features=50, out_features=50)\n",
       "  (ac_1): Tanh()\n",
       "  (output): Linear(in_features=50, out_features=2)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.apply(_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25241929"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc_0.weight.data.numpy().var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020535447"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc_1.weight.data.numpy().var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.018865753"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output.weight.data.numpy().var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
