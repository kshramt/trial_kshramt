{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport lib_prm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 75 17.0\n",
      "8 170 28.0\n",
      "12 250 15.0\n",
      "16 312 10.0\n",
      "20 344 8.0\n",
      "24 376 9.0\n",
      "28 411 10.0\n",
      "32 445 8.0\n",
      "36 481 10.0\n",
      "40 529 10.0\n",
      "44 579 13.0\n",
      "48 804 79.0\n",
      "52 1280 113.0\n",
      "56 2057 320.0\n",
      "60 3183 197.0\n",
      "64 4098 342.0\n",
      "68 5311 179.0\n",
      "72 6358 318.0\n",
      "76 7966 260.0\n",
      "80 9415 142.0\n",
      "84 11261 1000.0\n",
      "88 13208 106.0\n",
      "92 14228 303.0\n",
      "96 16330 1000.0\n",
      "100 18748 451.0\n",
      "104 20058 153.0\n",
      "108 20839 160.0\n",
      "112 22100 201.0\n",
      "116 24279 348.0\n",
      "120 25324 136.0\n",
      "124 26969 469.0\n",
      "128 29047 178.0\n",
      "132 29849 180.0\n",
      "136 30545 237.0\n",
      "140 32065 291.0\n",
      "144 32497 130.0\n",
      "148 33352 141.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-96367d334562>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_target_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi_total_step\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/p/trial_kshramt/RL/dqn_invader/prm.py\u001b[0m in \u001b[0;36msort\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_push_down\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/p/trial_kshramt/RL/dqn_invader/prm.py\u001b[0m in \u001b[0;36m_push_down\u001b[0;34m(self, i, limit)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mimax\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v0\").unwrapped\n",
    "\n",
    "n_middle_feature = 100\n",
    "n_middle_advantage = 50\n",
    "n_middle_value = 50\n",
    "n_input = env.observation_space.shape[0]\n",
    "n_output = env.action_space.n\n",
    "\n",
    "model_type = \"dueling\"\n",
    "#model_type = \"single\"\n",
    "if model_type == \"dueling\":\n",
    "    namer = lib_prm.make_namer()\n",
    "    feater_output = torch.nn.Linear(n_middle_feature, n_middle_feature)\n",
    "    feature = torch.nn.Sequential(collections.OrderedDict([\n",
    "        (namer(\"fc\"), torch.nn.Linear(n_input, n_middle_feature)),\n",
    "        (namer(\"ac\"), torch.nn.Tanh()),\n",
    "        (namer(\"fc\"), torch.nn.Linear(n_middle_feature, n_middle_feature)),\n",
    "        (namer(\"ac\"), torch.nn.Tanh()),\n",
    "        (namer(\"fc\"), feater_output),\n",
    "        (namer(\"ac\"), torch.nn.Tanh()),\n",
    "    ]))\n",
    "    namer = lib_prm.make_namer()\n",
    "    advantage = torch.nn.Sequential(collections.OrderedDict([\n",
    "        (namer(\"fc\"), torch.nn.Linear(n_middle_feature, n_middle_advantage)),\n",
    "        (namer(\"ac\"), torch.nn.Tanh()),\n",
    "        (namer(\"fc\"), torch.nn.Linear(n_middle_advantage, n_middle_advantage)),\n",
    "        (namer(\"ac\"), torch.nn.Tanh()),\n",
    "        (namer(\"fc\"), torch.nn.Linear(n_middle_advantage, n_output)),\n",
    "        (namer(\"mean0\"), lib_prm.Mean0()),\n",
    "    ]))\n",
    "    namer = lib_prm.make_namer()\n",
    "    value = torch.nn.Sequential(collections.OrderedDict([\n",
    "        (namer(\"fc\"), torch.nn.Linear(n_middle_feature, n_middle_value)),\n",
    "        (namer(\"ac\"), torch.nn.Tanh()),\n",
    "        (namer(\"fc\"), torch.nn.Linear(n_middle_value, n_middle_value)),\n",
    "        (namer(\"ac\"), torch.nn.Tanh()),\n",
    "        (namer(\"fc\"), torch.nn.Linear(n_middle_value, 1)),\n",
    "    ]))\n",
    "    model = lib_prm.Model(feature, value, advantage)\n",
    "elif model_type == \"single\":\n",
    "    namer = lib_prm.make_namer()\n",
    "    model = torch.nn.Sequential(collections.OrderedDict([\n",
    "        (namer(\"fc\"), torch.nn.Linear(n_input, n_middle_feature)),\n",
    "        (namer(\"ac\"), torch.nn.Tanh()),\n",
    "        (namer(\"fc\"), torch.nn.Linear(n_middle_feature, n_middle_feature)),\n",
    "        (namer(\"ac\"), torch.nn.Tanh()),\n",
    "        (namer(\"fc\"), torch.nn.Linear(n_middle_feature, n_middle_feature)),\n",
    "        (namer(\"ac\"), torch.nn.Tanh()),\n",
    "        (namer(\"fc\"), torch.nn.Linear(n_middle_feature, n_middle_feature)),\n",
    "        (namer(\"ac\"), torch.nn.Tanh()),\n",
    "        (namer(\"fc\"), torch.nn.Linear(n_middle_feature, n_middle_feature)),\n",
    "        (namer(\"ac\"), torch.nn.Tanh()),\n",
    "        (namer(\"fc\"), torch.nn.Linear(n_middle_feature, n_output)),\n",
    "    ]))\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported model_type: {model_type}\")\n",
    "model.apply(lib_prm.init_model)\n",
    "\n",
    "opt = torch.optim.SGD(model.parameters(), lr=3e-4, momentum=0.9)\n",
    "#opt = torch.optim.Adam(model.parameters(), lr=1e-3, eps=1e-3)\n",
    "\n",
    "n_replay_memory = 1_000_000\n",
    "n_batch = 31\n",
    "\n",
    "rm = lib_prm.prm.PrioritizedReplayMemory(capacity=n_replay_memory, n_batch=n_batch, alpha=0.5, random_state=42)\n",
    "loss = torch.nn.SmoothL1Loss()\n",
    "#loss = torch.nn.MSELoss()\n",
    "agent = lib_prm.Agent(model=model, opt=opt, gamma=0.99, replay_memory=rm, n_batch=n_batch, cuda=False, alpha=0.5, loss=loss, dqn_mode=\"doubledqn\", td_mode=\"mnih2015\")\n",
    "\n",
    "n_episodes = 1000\n",
    "n_steps = 1000\n",
    "n_steps_start = 300\n",
    "n_step_update = 50\n",
    "n_step_train = 1\n",
    "epsilon = 0.05\n",
    "\n",
    "i_total_step = 1\n",
    "for i_episode in range(1, n_episodes + 1):\n",
    "    si = env.reset()\n",
    "    r_episode = 0\n",
    "    for i_step in range(1, n_steps + 1):\n",
    "        if i_total_step <= n_steps_start:\n",
    "            ai1 = env.action_space.sample()\n",
    "        elif random.random() < epsilon:\n",
    "            ai1 = env.action_space.sample()\n",
    "        else:\n",
    "            ai1 = agent.act(si)\n",
    "        si1, ri1, done, _ = env.step(ai1)\n",
    "        r_episode += ri1\n",
    "        env.render()\n",
    "        import time\n",
    "        time.sleep(0.001)\n",
    "        agent.push(state=si, action=ai1, reward_next=ri1, state_next=si1, done=done)\n",
    "        if (i_total_step%n_step_train == 0) and (i_total_step > n_steps_start):\n",
    "            loss = agent.train()\n",
    "            #print(loss[\"loss\"].data.numpy()[0], np.std(loss[\"td\"].data.numpy()))\n",
    "        if i_total_step%n_step_update == 0:\n",
    "            agent.update_target_model()\n",
    "        if i_total_step%50 == 0:\n",
    "            agent.replay_memory.sort()\n",
    "        if done:\n",
    "            break\n",
    "        si = si1\n",
    "        i_total_step += 1\n",
    "    if i_episode%4 == 0:\n",
    "        print(i_episode, i_total_step, r_episode)\n",
    "        \n",
    "\n",
    "# env.reset()\n",
    "# for i in range(1000):\n",
    "#     env.render()\n",
    "#     a = env.action_space.sample()\n",
    "#     r = env.step(a)\n",
    "#     print(a, r[1:])\n",
    "#     time.sleep(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
